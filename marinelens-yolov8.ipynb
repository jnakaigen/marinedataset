{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Before you start\n\nLet's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`.","metadata":{"id":"FyRdDYkqAKN4"}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"Y8cDtxLIBHgQ","outputId":"11e643aa-a6f7-469a-e0d8-ac9ac4656d2f","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nHOME = os.getcwd()\nprint(HOME)","metadata":{"id":"CjpPg4mGKc1v","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Install YOLOv8\n\nYOLOv8 can be installed in two ways - from the source and via pip. This is because it is the first iteration of YOLO to have an official package.","metadata":{"id":"3C3EO_2zNChu"}},{"cell_type":"code","source":"# Pip install method (recommended)\n\n!pip install ultralytics==8.2.103 -q\n\nfrom IPython import display\ndisplay.clear_output()\n\n# prevent ultralytics from tracking your activity\n!yolo settings sync=False\n\nimport ultralytics\nultralytics.checks()","metadata":{"id":"tdSMcABDNKW-","outputId":"edb880c9-b3cc-4332-95e1-76bc475e072c","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\n\nfrom IPython.display import display, Image","metadata":{"id":"VOEYrlBoP9-E","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## CLI Basics","metadata":{"id":"HnnZSm5OQfPQ"}},{"cell_type":"markdown","source":"`yolo mode=predict` runs YOLOv8 inference on a variety of sources, downloading models automatically from the latest YOLOv8 release, and saving results to `runs/predict`.","metadata":{"id":"ZaE1kLS8R4CV"}},{"cell_type":"code","source":"!mkdir -p {HOME}/datasets\n%cd {HOME}/datasets\n\n!pip install roboflow\n\nfrom roboflow import Roboflow\nrf = Roboflow(api_key=\"vjy7mqsukngn19MU0R2t\")\nproject = rf.workspace(\"project-aunby\").project(\"microplastic-nuga5-nk7mh\")\nversion = project.version(2)\ndataset = version.download(\"yolov8\")\n","metadata":{"id":"BSd93ZJzZZKt","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Custom Training","metadata":{"id":"YUjFBKKqXa-u"}},{"cell_type":"code","source":"pip install -U ultralytics","metadata":{"trusted":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --upgrade ultralytics matplotlib","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd {HOME}\n\n!yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=25 imgsz=800 plots=True","metadata":{"id":"D2YkphuiaE7_","outputId":"33144669-1a6f-4168-9e1f-2661bb3dd5f0","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls /kaggle/working/runs/detect/train2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd {HOME}\nImage(filename=f'{HOME}/runs/detect/train2/confusion_matrix.png', width=600)","metadata":{"id":"_J35i8Ofhjxa","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd {HOME}\nImage(filename=f'{HOME}/runs/detect/train2/results.png', width=600)","metadata":{"id":"A-urTWUkhRmn","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd {HOME}\nImage(filename=f'{HOME}/runs/detect/train2/val_batch0_pred.jpg', width=600)","metadata":{"id":"HI4nADCCj3F5","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Validate Custom Model","metadata":{"id":"6ODk1VTlevxn"}},{"cell_type":"code","source":"%cd {HOME}\n\n!yolo task=detect mode=val model={HOME}/runs/detect/train2/weights/best.pt data={dataset.location}/data.yaml","metadata":{"id":"YpyuwrNlXc1P","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Inference with Custom Model","metadata":{"id":"i4eASbcWkQBq"}},{"cell_type":"code","source":"!ls /kaggle/working/datasets/MicroPlastic-2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd {HOME}\n!yolo task=detect mode=predict model={HOME}/runs/detect/train2/weights/best.pt conf=0.25 source={dataset.location}/valid/images save=True","metadata":{"id":"Wjc1ctZykYuf","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**NOTE:** Let's take a look at few results.","metadata":{"id":"mEYIo95n-I0S"}},{"cell_type":"code","source":"import glob\nfrom IPython.display import Image, display\n\n# Define the base path where the folders are located\nbase_path = '/kaggle/working/runs/detect/'\n\n# List all directories that start with 'predict' in the base path\nsubfolders = [os.path.join(base_path, d) for d in os.listdir(base_path)\n              if os.path.isdir(os.path.join(base_path, d)) and d.startswith('predict')]\n\n# Find the latest folder by modification time\nlatest_folder = max(subfolders, key=os.path.getmtime)\n\nimage_paths = glob.glob(f'{latest_folder}/*.jpg')[:3]\n\n# Display each image\nfor image_path in image_paths:\n    display(Image(filename=image_path, width=600))\n    print(\"\\n\")","metadata":{"id":"jbVjEtPAkz3j","outputId":"dc203df5-a15a-43bd-9026-3393b9bf7607","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Deploy model on Roboflow\n\nOnce you have finished training your YOLOv8 model, you’ll have a set of trained weights ready for use. These weights will be in the `/runs/detect/train/weights/best.pt` folder of your project. You can upload your model weights to Roboflow Deploy to use your trained weights on our infinitely scalable infrastructure.\n\nThe `.deploy()` function in the [Roboflow pip package](https://docs.roboflow.com/python) now supports uploading YOLOv8 weights.\n\nTo upload model weights, add the following code to the “Inference with Custom Model” section in the aforementioned notebook:","metadata":{"id":"j0tsVilOCPyq"}},{"cell_type":"code","source":"project.version(dataset.version).deploy(model_type=\"yolov8\", model_path=f\"{HOME}/runs/detect/train2/\")","metadata":{"id":"EbP4_4C8fc0R","outputId":"42a19e1c-5dcc-4795-d74e-8ed62c6db3c4","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Follow the links above to check if the upload succeeded. It may take a couple of minutes until the model is visible to the `roboflow` SDK.","metadata":{"id":"nQZk9Amyfq6F"}},{"cell_type":"code","source":"# Run inference on your model on a persistent, auto-scaling, cloud API\n\n# Load model\nmodel = project.version(dataset.version).model\nassert model, \"Model deployment is still loading\"\n\n# Choose a random test image\nimport os, random\ntest_set_loc = dataset.location + \"/test/images/\"\nrandom_test_image = random.choice(os.listdir(test_set_loc))\nprint(\"running inference on \" + random_test_image)\n\npred = model.predict(test_set_loc + random_test_image, confidence=40, overlap=30).json()\npred","metadata":{"id":"I4bpUIibcV1l","outputId":"a99c5232-7a21-4015-aa56-4512124ea660","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Deploy Your Model to the Edge\n\nIn addition to using the Roboflow hosted API for deployment, you can use [Roboflow Inference](https://inference.roboflow.com), an open source inference solution that has powered millions of API calls in production environments. Inference works with CPU and GPU, giving you immediate access to a range of devices, from the NVIDIA Jetson to TRT-compatible devices to ARM CPU devices.\n\nWith Roboflow Inference, you can self-host and deploy your model on-device. You can deploy applications using the [Inference Docker containers](https://inference.roboflow.com/quickstart/docker/) or the pip package.\n\nFor example, to install Inference on a device with an NVIDIA GPU, we can use:\n\n```\ndocker pull roboflow/roboflow-inference-server-gpu\n```\n\nThen we can run inference via HTTP:\n\n```python\nimport requests\n\nworkspace_id = \"\"\nmodel_id = \"\"\nimage_url = \"\"\nconfidence = 0.75\napi_key = \"\"\n\ninfer_payload = {\n    \"image\": {\n        \"type\": \"url\",\n        \"value\": image_url,\n    },\n    \"confidence\": confidence,\n    \"iou_threshold\": iou_thresh,\n    \"api_key\": api_key,\n}\nres = requests.post(\n    f\"http://localhost:9001/{workspace_id}/{model_id}\",\n    json=infer_object_detection_payload,\n)\n\npredictions = res.json()\n```\n\nAbove, set your Roboflow workspace ID, model ID, and API key.\n\n- [Find your workspace and model ID](https://docs.roboflow.com/api-reference/workspace-and-project-ids?ref=blog.roboflow.com)\n- [Find your API key](https://docs.roboflow.com/api-reference/authentication?ref=blog.roboflow.com#retrieve-an-api-key)\n\nAlso, set the URL of an image on which you want to run inference. This can be a local file.\n\n_To use your YOLOv5 model commercially with Inference, you will need a Roboflow Enterprise license, through which you gain a pass-through license for using YOLOv5. An enterprise license also grants you access to features like advanced device management, multi-model containers, auto-batch inference, and more._","metadata":{"id":"0ZRK3zxS2m1n"}}]}